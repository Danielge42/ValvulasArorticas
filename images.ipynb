{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from tensorflow.image import resize\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Codigo básico de lectura de números escritos a mano con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset mnist es un conjunto de imágenes negras con números blancos escritos a mano.Estos son los datos que usaremos para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (grayscale)\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape images to (28, 28, 1) to add the channel dimension (since Conv2D expects 4D input)\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo, con una red neuronal convolucional la cuyos números son: 32:cantidad de filtros usados. 3:dimensiones del filtro (matriz 3x3), input shape son las dimensiones de la imágen y padding=same significa que la matriz de mapeo será de las mismas dimensiones que la matriz de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#armar model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, 3, input_shape=(28, 28, 1), activation='relu', padding='same'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "##Dropout significa que se apaga el 20% de las neuronas para controlar el overfitting\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "##BatchNormalization normaliza las activaciones de la capa anterior en cada batch\n",
    "model.add(keras.layers.Flatten())\n",
    "##Flatten convierte la matriz de entrada en un vector\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "##Dense es la capa de salida con 10 neuronas y función de activación softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 145s 152ms/step - loss: 0.1590 - accuracy: 0.9517 - val_loss: 0.0841 - val_accuracy: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf1d624070>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se entrena el modelo\n",
    "model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0841 - accuracy: 0.9726\n",
      "Test accuracy: 0.972599983215332\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "#Usamos imagenes de minst\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images[3], cmap='gray_r')\n",
    "plt.title(f'Predicted: {predictions[3].argmax()}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para preprocesar la imagen\n",
    "\n",
    "from PIL import ImageOps\n",
    "\n",
    "def preprocess_custom_image(image_path):\n",
    "    # Cargar la imagen\n",
    "    img = Image.open(image_path).convert('L')  # Convert to grayscale (L mode)\n",
    "    \n",
    "    # Invert the image (optional: if the background is white and the digit is black)\n",
    "    img = ImageOps.invert(img)\n",
    "\n",
    "    # Resize to 28x28 pixels\n",
    "    img = img.resize((28, 28))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    \n",
    "  \n",
    "    img_array = img_array.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict custom images\n",
    "def predict_custom_image(image_path):\n",
    "    img_array = preprocess_custom_image(image_path)\n",
    "    \n",
    "    # Predict the class\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    # Find the class with the highest probability\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    print(f\"Predicted class: {predicted_class[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 220ms/step\n",
      "Predicted class: 4\n"
     ]
    }
   ],
   "source": [
    "# Test with your own image\n",
    "predict_custom_image('my_digit4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.66252846e-01, 8.72088546e-01, 5.69375517e-01, 7.23899648e-01,\n",
       "        1.98322393e-01, 4.81353360e-01, 4.89850146e-01, 8.71070259e-01,\n",
       "        7.22169816e-01, 5.70452355e-01, 3.89775352e-01, 3.03519658e-01,\n",
       "        3.60160739e-01, 1.57142546e-01, 9.50143976e-01, 3.94707086e-01,\n",
       "        1.75929431e-01, 7.65646811e-01, 5.46388305e-01, 1.54499921e-01,\n",
       "        3.58413057e-02, 1.20904829e-01, 4.81826622e-01, 2.62117557e-01,\n",
       "        1.35230866e-01, 3.49933497e-01, 6.09151771e-01, 5.95169023e-01],\n",
       "       [1.48359902e-01, 3.86991366e-01, 8.44571348e-01, 8.30821624e-01,\n",
       "        2.25302632e-03, 2.48085312e-01, 9.77557123e-01, 8.42950462e-01,\n",
       "        2.84811578e-01, 5.98909701e-01, 3.42769425e-01, 7.04120535e-01,\n",
       "        8.67812296e-01, 9.53045950e-01, 8.73930907e-02, 6.78592036e-01,\n",
       "        7.73866777e-01, 1.88855145e-01, 4.71818476e-01, 4.89470514e-01,\n",
       "        9.07668889e-02, 8.93417736e-02, 5.88603533e-01, 8.49451544e-01,\n",
       "        6.32729408e-01, 8.69814021e-01, 7.70827054e-01, 3.07982311e-01],\n",
       "       [7.24754494e-01, 2.77863804e-01, 7.69812091e-01, 2.96634893e-01,\n",
       "        6.90625492e-01, 9.81207614e-01, 7.84298119e-01, 9.61165081e-01,\n",
       "        9.85763636e-01, 8.86726896e-01, 1.26045253e-01, 9.48228001e-01,\n",
       "        5.80275256e-01, 9.29608678e-01, 5.97126476e-01, 3.84504816e-01,\n",
       "        5.26161002e-01, 4.66032850e-01, 6.44979518e-01, 3.45772961e-01,\n",
       "        2.62208762e-01, 1.51649554e-01, 2.64737012e-01, 1.59645162e-01,\n",
       "        7.30043557e-01, 3.95385190e-01, 2.09889350e-01, 1.68785314e-01],\n",
       "       [5.67665922e-01, 2.42986937e-01, 4.40264374e-01, 2.08785012e-01,\n",
       "        3.72515963e-01, 6.69796408e-01, 1.52756271e-01, 6.36052190e-01,\n",
       "        8.05629527e-01, 3.19000341e-02, 5.50922297e-01, 7.20009284e-01,\n",
       "        7.61009961e-01, 8.76869088e-01, 6.94827338e-01, 6.93657012e-01,\n",
       "        7.61949828e-01, 7.80405208e-01, 3.15481098e-01, 9.50260997e-01,\n",
       "        9.13360991e-02, 3.79555039e-01, 3.60054718e-01, 9.46554426e-01,\n",
       "        6.16715061e-01, 5.96440000e-02, 9.39291105e-01, 9.80585392e-02],\n",
       "       [9.25336630e-02, 7.34921354e-01, 3.96637269e-02, 4.96448313e-01,\n",
       "        6.64811871e-01, 4.38472229e-01, 7.85612384e-01, 8.50055142e-02,\n",
       "        8.22151371e-01, 8.06362708e-01, 3.91234960e-01, 1.26531308e-01,\n",
       "        7.90785575e-01, 2.03090932e-03, 4.81674979e-01, 4.70134815e-01,\n",
       "        7.10666827e-01, 7.15193791e-01, 8.08572760e-02, 3.29879244e-01,\n",
       "        6.26523153e-01, 7.83704687e-01, 2.84017296e-01, 8.15260382e-01,\n",
       "        8.55000280e-01, 6.66591862e-01, 1.33816006e-01, 3.45744312e-01],\n",
       "       [5.42369372e-02, 9.09634809e-01, 4.86446754e-01, 5.24212461e-01,\n",
       "        5.17515461e-02, 7.40561493e-01, 3.23720431e-01, 5.60355806e-02,\n",
       "        3.61492666e-01, 6.62217535e-04, 5.98072558e-01, 3.55821937e-01,\n",
       "        4.43640307e-01, 6.12803169e-01, 6.24175566e-01, 7.60600059e-01,\n",
       "        9.10768899e-01, 1.14080862e-01, 7.19230147e-01, 5.12704431e-01,\n",
       "        7.55958639e-01, 7.71577743e-01, 8.98261497e-01, 4.96610160e-01,\n",
       "        2.25294058e-01, 5.13313844e-01, 9.49808315e-01, 7.62611410e-01],\n",
       "       [7.87888142e-01, 1.57658425e-01, 2.55302774e-01, 1.61165995e-01,\n",
       "        7.43918475e-01, 2.00933252e-01, 2.75474270e-01, 1.58691823e-01,\n",
       "        6.88698993e-01, 4.75803147e-01, 4.08312356e-01, 3.40063449e-01,\n",
       "        6.25719878e-01, 5.17749829e-01, 5.41330725e-02, 7.34390009e-01,\n",
       "        4.85841901e-01, 7.17297220e-01, 9.39177181e-01, 9.36871860e-01,\n",
       "        3.82839849e-02, 2.07194946e-01, 5.39650257e-02, 6.21438984e-01,\n",
       "        1.46873329e-01, 5.05910425e-01, 6.73722799e-01, 4.49826358e-01],\n",
       "       [2.16586093e-01, 8.33850069e-01, 9.34853632e-01, 8.10958647e-01,\n",
       "        6.78824500e-01, 7.34889653e-01, 5.27295000e-01, 9.78613905e-01,\n",
       "        9.18974357e-01, 8.31834877e-01, 7.59765498e-01, 5.26365333e-01,\n",
       "        8.05942550e-02, 8.80496465e-01, 1.77612059e-01, 2.55293126e-01,\n",
       "        7.53824882e-01, 8.97442995e-02, 2.44158137e-02, 7.47086145e-02,\n",
       "        2.71817411e-01, 1.62526251e-01, 3.21137649e-01, 3.27019227e-01,\n",
       "        5.48933276e-01, 2.88612658e-01, 7.02205664e-01, 9.99795281e-02],\n",
       "       [2.85808535e-01, 1.04286975e-01, 2.98854743e-01, 4.62101735e-01,\n",
       "        3.38187180e-01, 7.55962192e-01, 8.32017742e-01, 2.96496581e-01,\n",
       "        5.07775181e-02, 9.17304082e-01, 2.13275977e-01, 3.09377405e-01,\n",
       "        6.14026693e-01, 4.01771417e-02, 6.19507924e-01, 1.69336388e-01,\n",
       "        9.26658601e-01, 4.03438599e-02, 1.45501932e-01, 4.54988943e-01,\n",
       "        5.89647378e-01, 4.35943957e-01, 8.65338231e-01, 7.10865889e-01,\n",
       "        6.66973139e-01, 3.98437790e-01, 6.82410393e-01, 9.42415100e-01],\n",
       "       [5.90478827e-01, 9.80656850e-01, 6.89498946e-01, 1.84875000e-01,\n",
       "        8.98847557e-01, 8.90251642e-01, 5.62244042e-01, 1.38234956e-01,\n",
       "        5.02608603e-01, 6.92350384e-01, 4.82688783e-02, 8.21238046e-01,\n",
       "        2.54905330e-01, 1.05126654e-01, 5.91208210e-01, 5.47666461e-02,\n",
       "        9.09856752e-01, 9.57437009e-01, 4.91588027e-02, 9.22063804e-01,\n",
       "        9.29505433e-01, 7.41803495e-01, 3.07661746e-01, 7.45912333e-01,\n",
       "        3.72878147e-01, 5.28936963e-01, 5.91416383e-01, 7.12377229e-01],\n",
       "       [8.76464155e-01, 4.05718291e-01, 9.11621360e-01, 3.18033081e-01,\n",
       "        8.06101836e-01, 7.34172700e-01, 6.88864090e-01, 9.10065521e-01,\n",
       "        1.99649761e-01, 8.48080051e-02, 5.76545080e-01, 8.83728772e-02,\n",
       "        7.16246648e-01, 3.80641612e-01, 3.86548427e-01, 1.24635363e-01,\n",
       "        3.30220621e-01, 9.00873608e-01, 6.94022249e-01, 6.77384082e-02,\n",
       "        3.72558846e-01, 3.67190346e-01, 8.67825646e-01, 5.49641941e-01,\n",
       "        8.76440828e-01, 6.20408708e-01, 3.98866765e-01, 1.48631019e-01],\n",
       "       [9.15634696e-01, 3.53209591e-01, 7.26447446e-01, 1.12161642e-01,\n",
       "        3.04544200e-02, 7.34496350e-01, 6.20647317e-01, 1.02744969e-01,\n",
       "        1.25622186e-01, 3.74853952e-01, 9.56453817e-01, 7.12284180e-01,\n",
       "        1.35967103e-01, 9.52856416e-02, 6.93677607e-01, 4.71088550e-01,\n",
       "        2.65825862e-01, 8.69747580e-01, 2.91880751e-01, 6.68667063e-01,\n",
       "        2.09006507e-01, 8.80250320e-01, 1.55651562e-01, 3.73333870e-01,\n",
       "        5.99762324e-01, 6.06181134e-02, 9.00425668e-01, 5.28353296e-01],\n",
       "       [5.66164349e-01, 9.72121410e-01, 9.93002131e-01, 9.56962379e-01,\n",
       "        8.79565590e-02, 4.28016596e-01, 8.21183258e-01, 3.73881877e-01,\n",
       "        8.05365806e-01, 5.82850188e-01, 5.52697270e-01, 3.35290989e-01,\n",
       "        1.38417519e-01, 3.34353519e-01, 3.62911215e-01, 1.90965793e-01,\n",
       "        2.01657027e-01, 6.91858884e-01, 3.81131473e-01, 8.75512343e-01,\n",
       "        8.04941076e-01, 9.53893359e-01, 1.37425815e-01, 1.43641988e-01,\n",
       "        9.59341695e-01, 1.22901391e-01, 5.93271083e-01, 2.15600324e-01],\n",
       "       [2.11647057e-01, 8.27891194e-01, 5.16426201e-01, 9.11447292e-02,\n",
       "        2.58672106e-01, 5.51975346e-01, 8.79608293e-01, 7.58146364e-01,\n",
       "        5.29021950e-01, 1.72793433e-01, 1.63976154e-02, 8.59782030e-01,\n",
       "        2.34555681e-01, 9.26373601e-01, 2.01141020e-01, 6.30047778e-01,\n",
       "        6.10706915e-01, 4.32300413e-02, 9.98605301e-01, 1.11560328e-01,\n",
       "        9.79371091e-01, 7.10661317e-01, 4.00184584e-01, 1.75492815e-01,\n",
       "        1.82209992e-01, 9.86709566e-01, 1.18527517e-01, 8.96962965e-01],\n",
       "       [8.29350232e-01, 9.19589418e-01, 8.90631630e-01, 5.24404962e-01,\n",
       "        1.70259378e-02, 4.64108053e-02, 4.98352098e-03, 6.29533596e-02,\n",
       "        8.88822250e-01, 5.44497216e-01, 9.79635088e-01, 5.34278153e-01,\n",
       "        7.62963085e-02, 8.35470501e-01, 2.73016993e-01, 4.37645713e-01,\n",
       "        5.77280404e-02, 8.39862398e-01, 9.96803175e-01, 1.10430372e-01,\n",
       "        5.81815757e-01, 2.02568957e-01, 1.98636444e-01, 8.45667144e-01,\n",
       "        5.68527689e-01, 8.98291604e-01, 1.73413320e-01, 9.11362163e-02],\n",
       "       [5.25944952e-02, 5.98246872e-01, 4.65779458e-01, 5.11177001e-01,\n",
       "        9.54558378e-01, 1.70495509e-01, 3.36783784e-01, 1.77690982e-01,\n",
       "        2.01364197e-01, 7.54864453e-01, 4.81927460e-01, 8.33041938e-01,\n",
       "        3.04316303e-01, 3.47756030e-01, 7.08585768e-02, 3.35818232e-01,\n",
       "        3.19304363e-01, 7.47017747e-01, 3.76862032e-01, 3.94962563e-01,\n",
       "        9.39299220e-01, 4.60855025e-01, 1.32880692e-02, 8.84749280e-01,\n",
       "        4.58112968e-01, 8.65496998e-01, 3.39382341e-01, 8.29414967e-01],\n",
       "       [4.89942155e-01, 5.72455399e-01, 6.00736344e-02, 9.76505598e-01,\n",
       "        9.79447678e-01, 8.45583786e-01, 5.56890238e-01, 3.02515896e-02,\n",
       "        9.29528052e-01, 4.19123620e-01, 8.82810485e-01, 1.42288392e-01,\n",
       "        7.65032159e-01, 8.96083958e-02, 2.46071881e-01, 6.90462847e-01,\n",
       "        2.34308335e-01, 8.01347010e-01, 8.75471235e-01, 2.37273588e-02,\n",
       "        9.58943513e-01, 6.28821325e-01, 2.84204873e-01, 2.81738748e-01,\n",
       "        6.70921865e-01, 8.49495528e-01, 5.56451078e-01, 9.96652344e-01],\n",
       "       [1.99451548e-01, 9.68627892e-02, 5.41739934e-01, 9.43584861e-01,\n",
       "        1.22319362e-01, 8.40682492e-01, 6.54166280e-01, 6.48871945e-01,\n",
       "        6.67272681e-01, 6.63739026e-01, 3.76169273e-01, 6.22093804e-01,\n",
       "        6.78645896e-01, 1.69737632e-02, 7.65708844e-01, 7.01533272e-01,\n",
       "        7.52532558e-01, 2.88912212e-01, 2.94775707e-01, 5.41667168e-01,\n",
       "        8.53432153e-01, 1.94830127e-01, 5.17603299e-01, 3.78731792e-02,\n",
       "        2.01012285e-01, 1.58751993e-01, 4.73453593e-01, 6.68045081e-02],\n",
       "       [7.76167071e-01, 6.12589362e-01, 2.30318972e-01, 1.63123130e-01,\n",
       "        9.77631789e-01, 9.07564663e-01, 8.63762937e-01, 9.96802824e-01,\n",
       "        5.30619911e-01, 8.19254185e-01, 5.67819312e-01, 1.96219040e-01,\n",
       "        3.22823310e-01, 6.18982737e-01, 9.54894795e-01, 3.72507803e-02,\n",
       "        1.30449256e-01, 1.24116199e-01, 5.84006846e-01, 8.98793387e-01,\n",
       "        6.29541984e-02, 6.35874679e-01, 5.88301584e-01, 1.48965515e-01,\n",
       "        8.09230718e-02, 6.54060795e-01, 8.20714410e-02, 6.69114289e-01],\n",
       "       [5.15767277e-01, 1.27037005e-01, 2.21802374e-01, 5.83933177e-01,\n",
       "        3.28526908e-02, 8.74288728e-01, 4.65263890e-01, 3.25790560e-01,\n",
       "        2.55512730e-01, 8.45089912e-02, 7.99329085e-01, 8.63874707e-01,\n",
       "        3.36152737e-01, 6.11443619e-02, 4.92709457e-01, 9.68833308e-01,\n",
       "        1.15542408e-01, 5.62609679e-01, 8.94753327e-01, 4.50457476e-01,\n",
       "        7.26682417e-02, 8.87413855e-01, 6.72612395e-01, 9.19439845e-01,\n",
       "        3.32243965e-01, 1.67439065e-01, 8.41196958e-01, 4.52603497e-01],\n",
       "       [7.43148137e-01, 7.38888941e-01, 7.44617746e-01, 1.59927453e-01,\n",
       "        3.39408813e-01, 3.02198229e-02, 2.16751043e-01, 6.23592422e-01,\n",
       "        1.97387573e-01, 3.39575794e-01, 2.85381608e-01, 3.04130191e-01,\n",
       "        4.23350756e-01, 1.52935222e-01, 7.59136463e-01, 6.36743604e-01,\n",
       "        7.76453751e-01, 8.85733461e-01, 2.83490797e-01, 9.87053490e-01,\n",
       "        8.90584388e-01, 9.58140724e-02, 7.80949487e-01, 2.29647731e-01,\n",
       "        4.53536284e-01, 7.62623549e-01, 8.20263865e-01, 6.35409776e-01],\n",
       "       [8.07969883e-01, 9.66639750e-01, 2.77095754e-01, 5.50635662e-01,\n",
       "        3.06451213e-01, 7.76656212e-01, 8.55217362e-01, 7.27961959e-01,\n",
       "        2.11567525e-01, 1.65209709e-01, 8.27438029e-01, 6.01474373e-01,\n",
       "        3.16944311e-01, 6.68598993e-01, 3.79011827e-01, 7.43142182e-01,\n",
       "        3.28590645e-01, 7.03588804e-02, 2.87224212e-01, 3.01758241e-01,\n",
       "        4.72729208e-01, 1.37661954e-01, 5.93911530e-03, 6.69741107e-02,\n",
       "        9.25292269e-01, 3.03112903e-01, 8.70581125e-01, 2.12010944e-01],\n",
       "       [9.01568734e-01, 8.61887306e-01, 6.64731479e-02, 1.51679116e-01,\n",
       "        9.70809994e-01, 5.96487098e-01, 2.35162449e-01, 5.59269154e-01,\n",
       "        1.89376985e-01, 7.01360144e-01, 6.14652290e-01, 8.89893608e-01,\n",
       "        1.20864260e-01, 7.90804644e-01, 5.18954907e-01, 4.11742460e-01,\n",
       "        5.24917469e-01, 6.16769096e-01, 5.34560267e-01, 9.82828595e-02,\n",
       "        8.94019989e-01, 3.32178821e-01, 1.28598700e-01, 7.66133110e-01,\n",
       "        9.32658589e-01, 6.63745722e-01, 2.89142983e-01, 7.17837236e-01],\n",
       "       [5.42989485e-01, 5.57556951e-01, 3.54686401e-01, 6.94780995e-01,\n",
       "        7.42197133e-01, 6.69088561e-01, 5.43572056e-01, 9.75007941e-01,\n",
       "        7.03267727e-01, 2.94537205e-01, 7.13812778e-02, 2.81520327e-01,\n",
       "        4.98028131e-01, 3.33931813e-01, 1.60616607e-01, 1.60213406e-01,\n",
       "        8.75952167e-01, 8.18989452e-01, 2.68172248e-01, 1.68664600e-01,\n",
       "        9.82683796e-02, 8.54666396e-01, 8.82864939e-01, 3.80844474e-01,\n",
       "        6.43738427e-01, 5.21316106e-01, 4.73093572e-01, 6.58666237e-01],\n",
       "       [6.44620918e-01, 3.65675682e-01, 9.69461832e-01, 9.71665282e-02,\n",
       "        6.92592340e-01, 4.66743624e-01, 7.46890855e-01, 6.14828401e-01,\n",
       "        4.78955029e-01, 4.52649216e-02, 1.08112519e-01, 7.25768952e-01,\n",
       "        2.51476271e-01, 2.15229957e-01, 9.56298887e-01, 4.07498132e-01,\n",
       "        3.76689347e-01, 7.94548836e-01, 5.78588700e-01, 6.46033949e-01,\n",
       "        3.18089762e-01, 3.55516146e-01, 8.19884859e-01, 9.20814504e-02,\n",
       "        3.82487984e-01, 4.99469354e-01, 1.56112578e-01, 5.28565920e-01],\n",
       "       [4.46697247e-01, 1.42776686e-01, 5.60016007e-02, 4.62312546e-01,\n",
       "        8.08458939e-01, 4.22706862e-01, 9.69766921e-01, 1.49076462e-01,\n",
       "        7.21075234e-01, 1.02022032e-01, 6.81561349e-01, 7.41553878e-01,\n",
       "        9.82748883e-01, 6.08526207e-01, 9.29619354e-01, 7.64226195e-01,\n",
       "        7.92670258e-01, 9.64407904e-01, 5.93415048e-01, 7.09630792e-02,\n",
       "        8.93494260e-01, 7.45800619e-01, 2.80901233e-01, 8.07683877e-02,\n",
       "        5.28873210e-01, 8.91352903e-01, 7.81764587e-01, 5.12956115e-01],\n",
       "       [6.76536392e-01, 4.26100526e-01, 5.42296564e-01, 6.95159243e-01,\n",
       "        6.04954162e-01, 3.30942392e-01, 5.09556097e-01, 3.91512158e-01,\n",
       "        1.33192103e-01, 4.98006927e-01, 4.27102718e-01, 7.26431105e-01,\n",
       "        5.95393298e-02, 3.65823542e-01, 8.43585193e-01, 5.01683054e-01,\n",
       "        7.59851038e-01, 6.16966641e-01, 4.91181231e-01, 6.22059941e-01,\n",
       "        9.84106729e-01, 8.95766521e-01, 7.00270389e-01, 9.93883896e-02,\n",
       "        1.59292334e-01, 9.26497122e-01, 8.02154608e-01, 5.02075454e-01],\n",
       "       [1.38020118e-01, 7.13456126e-01, 7.71785532e-01, 3.87377651e-01,\n",
       "        7.71258002e-01, 5.18136462e-01, 9.63822825e-01, 6.83660891e-01,\n",
       "        5.89798497e-01, 5.11300475e-01, 2.56389500e-01, 7.19974988e-02,\n",
       "        6.51154947e-01, 3.68344005e-02, 4.04771042e-01, 7.77042762e-01,\n",
       "        2.10894742e-01, 1.65593793e-02, 2.06421512e-01, 2.65506564e-01,\n",
       "        8.74444493e-01, 5.89441717e-01, 8.99389408e-01, 5.16278775e-01,\n",
       "        2.41473009e-01, 5.14064817e-01, 4.61215694e-01, 3.32128317e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv2D(input_image, kernel, stride = 1, padding = 0):\n",
    "    # Add padding to the input image\n",
    "    if padding > 0:\n",
    "        input_image = np.pad(input_image, ((padding, padding), (padding, padding)), mode='constant', constant_values=0)\n",
    "\n",
    "    # Dimensions of input image and kernel\n",
    "    input_height, input_width = input_image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    # Calculate output dimensions\n",
    "    output_height = (input_height - kernel_height) // stride + 1\n",
    "    output_width = (input_width - kernel_width) // stride + 1\n",
    "    # Initialize the output feature map\n",
    "    output = np.zeros((output_height, output_width))\n",
    "        # Perform the convolution operation\n",
    "    for y in range(0, output_height):\n",
    "        for x in range(0, output_width):\n",
    "            # Extract the patch of the image\n",
    "            patch = input_image[y * stride:y * stride + kernel_height, x * stride:x * stride + kernel_width]\n",
    "\n",
    "            # Perform element-wise multiplication and sum the result\n",
    "            output[y, x] = np.sum(patch * kernel)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
